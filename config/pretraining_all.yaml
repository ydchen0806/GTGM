NAME: 'pretraining_all'

MODEL:
    model_type: 'superhuman'  # 'mala' or 'superhuman' or 'UNETR'
    input_nc: 1
    output_nc: 1
    return_dict: False
    unetr_size: [32,160,160]
    patch_size: [4,16,16]
    kernel_size: [1,3,3]
    if_sigmoid: True
    match_name: True
    # for 'mala':
    init_mode_mala: 'kaiming'
    # for 'superhuman':
    filters: 
        - 28
        - 36
        - 48
        - 64
        - 80
    upsample_mode: 'transposeS'  # 'bilinear', 'nearest', 'transpose', 'transposeS'
    decode_ratio: 1
    merge_mode: 'cat'  # 'add', 'cat'
    pad_mode: 'zero'  # 'zero', 'replicate'
    bn_mode: 'async'  # 'sync', 'async'
    relu_mode: 'elu'  # 'elu', 'relu', 'leaky'
    init_mode: 'kaiming_normal'  # 'kaiming_normal', 'kaiming_uniform', 'xavier_normal', 'xavier_uniform'

TRAIN:
    resume: False
    if_valid: True
    cache_path: '/braindat/lab/chenyd/RESULT/miccai23_cashes'
    save_path: '/braindat/lab/chenyd/MODEL/miccai23_models' 
    record_path: '/braindat/lab/chenyd/LOGs/miccai23_models'
    caption_path: '/braindat/lab/chenyd/DATASET/offline_caption'
    pad: 0
    loss_func: 'MSE'   # 'MSE', 'L1'
    random_choice: False
    multi_scale_mse: False
    free_layers: 9
    opt_type: 'adam'
    total_iters: 500000
    warmup_iters: 0
    base_lr: 0.0001
    end_lr: 0.00001
    display_freq: 100
    valid_freq: 500
    save_freq: 1000
    decay_iters: 200000
    weight_decay: 1e-9
    power: 1.5

    batch_size: 16
    num_workers: 4
    if_cuda: True

    random_seed: 555  # -1 is none

DATA:
    dataset_name: 'cremi-C'  # 'snemi3d-ac3', 'cremi-C'
    unlabel_dataset: 'cremi-C-200'  # 'ac3_ac4', 'ac4_around', 'cremi-C-200', 'cremi-all'
    type: 'EM' # 'CT', 'MRI', 'EM','all'
    unlabel_datalist: 
        - 'AC4_5.h5'
        - 'AC4_6.h5'
        - 'AC4_7.h5'
        - 'AC4_9.h5'
        - 'AC4_10.h5'
        - 'AC4_11.h5'
        - 'AC4_12.h5'
        - 'AC4_13.h5'
    folder_name: '/braindat/lab/chenyd/DATASET/miccai_pretrain_data'
    test_split: 25  # for speed
    unlabel_split: 100
    unlabel_split_rate: 1
    data_folder: './data'
    if_norm_images: False
    if_scale_aug_labeled: False
    scale_factor: 1.5
    if_filp_aug_labeled: False
    if_rotation_aug_labeled: False
    if_intensity_aug_labeled: False
    if_elastic_aug_labeled: False
    if_noise_aug_labeled: False
    min_noise_std: 0.01
    max_noise_std: 0.2
    if_mask_aug_labeled: False
    if_blur_aug_labeled: True
    min_kernel_size: 3
    max_kernel_size: 9
    min_sigma: 0
    max_sigma: 2

    per_mode: 1
    if_scale_aug_unlabel: False
    if_filp_aug_unlabel: True
    if_rotation_aug_unlabel: True
    if_intensity_aug_unlabel: True
    if_noise_aug_unlabel: True
    if_blur_aug_unlabel: True
    if_mask_aug_unlabel: False
    if_sobel_aug_unlabel: False
    if_mixup_aug_unlabel: False
    if_misalign_aug_unlabel: False
    if_elastic_aug_unlabel: False
    if_artifact_aug_unlabel: False
    if_missing_aug_unlabel: False
    if_blurenhanced_aug_unlabel: False

TEST:
    pad: 0
    model_name: ' '

network:
  img_model: resnet50
  ### this part does not control builder/trainer
  text_model: bert
  free_layers: 6
  text_model_arch: general # specialized/general
  feature_dim: 768

  projection_head:
    mlp_hidden_size: 2048
    projection_size: 768
  ###

### device setting control by torchrun, not this part
device_id: 0
device_num: 1
###

trainer:
  batch_size: 2
  test_batch_size: 200
  checkpoint_interval: 100000
  max_epochs: 200
  max_iterations: 200000
  lr: 2.0e-5
  num_workers: 8
  test_interval: 2
  loss: 'only_clip' # 
  smooth: 'exp' # you don't need smooth here, because no prior knowledege yet
  ratio: 0.2

optimizer:
  params:
    lr: 2.0e-5
    # momentum: 0.9
    weight_decay: 5.0e-2

wandb_name: 'generate_then_optimize_pretrain'