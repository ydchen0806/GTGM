{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 04:55:22.615271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 04:55:23.709579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-19 04:55:23.709687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-19 04:55:23.709699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.12.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /opt/conda/lib/python3.7/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.3.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: 4.6.0\n",
      "TorchVision version: 0.13.0\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.6.0\n",
      "transformers version: 4.26.1\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/braindat/lab/chenyd/LOGs/Neurips23_imgSSL/barlowTwins0414_final2/checkpoint_29999.pth'\n",
    "weight = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module.backbone.conv1.weight', 'module.backbone.bn1.weight', 'module.backbone.bn1.bias', 'module.backbone.bn1.running_mean', 'module.backbone.bn1.running_var', 'module.backbone.bn1.num_batches_tracked', 'module.backbone.layer1.0.conv1.weight', 'module.backbone.layer1.0.bn1.weight', 'module.backbone.layer1.0.bn1.bias', 'module.backbone.layer1.0.bn1.running_mean', 'module.backbone.layer1.0.bn1.running_var', 'module.backbone.layer1.0.bn1.num_batches_tracked', 'module.backbone.layer1.0.conv2.weight', 'module.backbone.layer1.0.bn2.weight', 'module.backbone.layer1.0.bn2.bias', 'module.backbone.layer1.0.bn2.running_mean', 'module.backbone.layer1.0.bn2.running_var', 'module.backbone.layer1.0.bn2.num_batches_tracked', 'module.backbone.layer1.0.conv3.weight', 'module.backbone.layer1.0.bn3.weight', 'module.backbone.layer1.0.bn3.bias', 'module.backbone.layer1.0.bn3.running_mean', 'module.backbone.layer1.0.bn3.running_var', 'module.backbone.layer1.0.bn3.num_batches_tracked', 'module.backbone.layer1.0.downsample.0.weight', 'module.backbone.layer1.0.downsample.1.weight', 'module.backbone.layer1.0.downsample.1.bias', 'module.backbone.layer1.0.downsample.1.running_mean', 'module.backbone.layer1.0.downsample.1.running_var', 'module.backbone.layer1.0.downsample.1.num_batches_tracked', 'module.backbone.layer1.1.conv1.weight', 'module.backbone.layer1.1.bn1.weight', 'module.backbone.layer1.1.bn1.bias', 'module.backbone.layer1.1.bn1.running_mean', 'module.backbone.layer1.1.bn1.running_var', 'module.backbone.layer1.1.bn1.num_batches_tracked', 'module.backbone.layer1.1.conv2.weight', 'module.backbone.layer1.1.bn2.weight', 'module.backbone.layer1.1.bn2.bias', 'module.backbone.layer1.1.bn2.running_mean', 'module.backbone.layer1.1.bn2.running_var', 'module.backbone.layer1.1.bn2.num_batches_tracked', 'module.backbone.layer1.1.conv3.weight', 'module.backbone.layer1.1.bn3.weight', 'module.backbone.layer1.1.bn3.bias', 'module.backbone.layer1.1.bn3.running_mean', 'module.backbone.layer1.1.bn3.running_var', 'module.backbone.layer1.1.bn3.num_batches_tracked', 'module.backbone.layer1.2.conv1.weight', 'module.backbone.layer1.2.bn1.weight', 'module.backbone.layer1.2.bn1.bias', 'module.backbone.layer1.2.bn1.running_mean', 'module.backbone.layer1.2.bn1.running_var', 'module.backbone.layer1.2.bn1.num_batches_tracked', 'module.backbone.layer1.2.conv2.weight', 'module.backbone.layer1.2.bn2.weight', 'module.backbone.layer1.2.bn2.bias', 'module.backbone.layer1.2.bn2.running_mean', 'module.backbone.layer1.2.bn2.running_var', 'module.backbone.layer1.2.bn2.num_batches_tracked', 'module.backbone.layer1.2.conv3.weight', 'module.backbone.layer1.2.bn3.weight', 'module.backbone.layer1.2.bn3.bias', 'module.backbone.layer1.2.bn3.running_mean', 'module.backbone.layer1.2.bn3.running_var', 'module.backbone.layer1.2.bn3.num_batches_tracked', 'module.backbone.layer2.0.conv1.weight', 'module.backbone.layer2.0.bn1.weight', 'module.backbone.layer2.0.bn1.bias', 'module.backbone.layer2.0.bn1.running_mean', 'module.backbone.layer2.0.bn1.running_var', 'module.backbone.layer2.0.bn1.num_batches_tracked', 'module.backbone.layer2.0.conv2.weight', 'module.backbone.layer2.0.bn2.weight', 'module.backbone.layer2.0.bn2.bias', 'module.backbone.layer2.0.bn2.running_mean', 'module.backbone.layer2.0.bn2.running_var', 'module.backbone.layer2.0.bn2.num_batches_tracked', 'module.backbone.layer2.0.conv3.weight', 'module.backbone.layer2.0.bn3.weight', 'module.backbone.layer2.0.bn3.bias', 'module.backbone.layer2.0.bn3.running_mean', 'module.backbone.layer2.0.bn3.running_var', 'module.backbone.layer2.0.bn3.num_batches_tracked', 'module.backbone.layer2.0.downsample.0.weight', 'module.backbone.layer2.0.downsample.1.weight', 'module.backbone.layer2.0.downsample.1.bias', 'module.backbone.layer2.0.downsample.1.running_mean', 'module.backbone.layer2.0.downsample.1.running_var', 'module.backbone.layer2.0.downsample.1.num_batches_tracked', 'module.backbone.layer2.1.conv1.weight', 'module.backbone.layer2.1.bn1.weight', 'module.backbone.layer2.1.bn1.bias', 'module.backbone.layer2.1.bn1.running_mean', 'module.backbone.layer2.1.bn1.running_var', 'module.backbone.layer2.1.bn1.num_batches_tracked', 'module.backbone.layer2.1.conv2.weight', 'module.backbone.layer2.1.bn2.weight', 'module.backbone.layer2.1.bn2.bias', 'module.backbone.layer2.1.bn2.running_mean', 'module.backbone.layer2.1.bn2.running_var', 'module.backbone.layer2.1.bn2.num_batches_tracked', 'module.backbone.layer2.1.conv3.weight', 'module.backbone.layer2.1.bn3.weight', 'module.backbone.layer2.1.bn3.bias', 'module.backbone.layer2.1.bn3.running_mean', 'module.backbone.layer2.1.bn3.running_var', 'module.backbone.layer2.1.bn3.num_batches_tracked', 'module.backbone.layer2.2.conv1.weight', 'module.backbone.layer2.2.bn1.weight', 'module.backbone.layer2.2.bn1.bias', 'module.backbone.layer2.2.bn1.running_mean', 'module.backbone.layer2.2.bn1.running_var', 'module.backbone.layer2.2.bn1.num_batches_tracked', 'module.backbone.layer2.2.conv2.weight', 'module.backbone.layer2.2.bn2.weight', 'module.backbone.layer2.2.bn2.bias', 'module.backbone.layer2.2.bn2.running_mean', 'module.backbone.layer2.2.bn2.running_var', 'module.backbone.layer2.2.bn2.num_batches_tracked', 'module.backbone.layer2.2.conv3.weight', 'module.backbone.layer2.2.bn3.weight', 'module.backbone.layer2.2.bn3.bias', 'module.backbone.layer2.2.bn3.running_mean', 'module.backbone.layer2.2.bn3.running_var', 'module.backbone.layer2.2.bn3.num_batches_tracked', 'module.backbone.layer2.3.conv1.weight', 'module.backbone.layer2.3.bn1.weight', 'module.backbone.layer2.3.bn1.bias', 'module.backbone.layer2.3.bn1.running_mean', 'module.backbone.layer2.3.bn1.running_var', 'module.backbone.layer2.3.bn1.num_batches_tracked', 'module.backbone.layer2.3.conv2.weight', 'module.backbone.layer2.3.bn2.weight', 'module.backbone.layer2.3.bn2.bias', 'module.backbone.layer2.3.bn2.running_mean', 'module.backbone.layer2.3.bn2.running_var', 'module.backbone.layer2.3.bn2.num_batches_tracked', 'module.backbone.layer2.3.conv3.weight', 'module.backbone.layer2.3.bn3.weight', 'module.backbone.layer2.3.bn3.bias', 'module.backbone.layer2.3.bn3.running_mean', 'module.backbone.layer2.3.bn3.running_var', 'module.backbone.layer2.3.bn3.num_batches_tracked', 'module.backbone.layer3.0.conv1.weight', 'module.backbone.layer3.0.bn1.weight', 'module.backbone.layer3.0.bn1.bias', 'module.backbone.layer3.0.bn1.running_mean', 'module.backbone.layer3.0.bn1.running_var', 'module.backbone.layer3.0.bn1.num_batches_tracked', 'module.backbone.layer3.0.conv2.weight', 'module.backbone.layer3.0.bn2.weight', 'module.backbone.layer3.0.bn2.bias', 'module.backbone.layer3.0.bn2.running_mean', 'module.backbone.layer3.0.bn2.running_var', 'module.backbone.layer3.0.bn2.num_batches_tracked', 'module.backbone.layer3.0.conv3.weight', 'module.backbone.layer3.0.bn3.weight', 'module.backbone.layer3.0.bn3.bias', 'module.backbone.layer3.0.bn3.running_mean', 'module.backbone.layer3.0.bn3.running_var', 'module.backbone.layer3.0.bn3.num_batches_tracked', 'module.backbone.layer3.0.downsample.0.weight', 'module.backbone.layer3.0.downsample.1.weight', 'module.backbone.layer3.0.downsample.1.bias', 'module.backbone.layer3.0.downsample.1.running_mean', 'module.backbone.layer3.0.downsample.1.running_var', 'module.backbone.layer3.0.downsample.1.num_batches_tracked', 'module.backbone.layer3.1.conv1.weight', 'module.backbone.layer3.1.bn1.weight', 'module.backbone.layer3.1.bn1.bias', 'module.backbone.layer3.1.bn1.running_mean', 'module.backbone.layer3.1.bn1.running_var', 'module.backbone.layer3.1.bn1.num_batches_tracked', 'module.backbone.layer3.1.conv2.weight', 'module.backbone.layer3.1.bn2.weight', 'module.backbone.layer3.1.bn2.bias', 'module.backbone.layer3.1.bn2.running_mean', 'module.backbone.layer3.1.bn2.running_var', 'module.backbone.layer3.1.bn2.num_batches_tracked', 'module.backbone.layer3.1.conv3.weight', 'module.backbone.layer3.1.bn3.weight', 'module.backbone.layer3.1.bn3.bias', 'module.backbone.layer3.1.bn3.running_mean', 'module.backbone.layer3.1.bn3.running_var', 'module.backbone.layer3.1.bn3.num_batches_tracked', 'module.backbone.layer3.2.conv1.weight', 'module.backbone.layer3.2.bn1.weight', 'module.backbone.layer3.2.bn1.bias', 'module.backbone.layer3.2.bn1.running_mean', 'module.backbone.layer3.2.bn1.running_var', 'module.backbone.layer3.2.bn1.num_batches_tracked', 'module.backbone.layer3.2.conv2.weight', 'module.backbone.layer3.2.bn2.weight', 'module.backbone.layer3.2.bn2.bias', 'module.backbone.layer3.2.bn2.running_mean', 'module.backbone.layer3.2.bn2.running_var', 'module.backbone.layer3.2.bn2.num_batches_tracked', 'module.backbone.layer3.2.conv3.weight', 'module.backbone.layer3.2.bn3.weight', 'module.backbone.layer3.2.bn3.bias', 'module.backbone.layer3.2.bn3.running_mean', 'module.backbone.layer3.2.bn3.running_var', 'module.backbone.layer3.2.bn3.num_batches_tracked', 'module.backbone.layer3.3.conv1.weight', 'module.backbone.layer3.3.bn1.weight', 'module.backbone.layer3.3.bn1.bias', 'module.backbone.layer3.3.bn1.running_mean', 'module.backbone.layer3.3.bn1.running_var', 'module.backbone.layer3.3.bn1.num_batches_tracked', 'module.backbone.layer3.3.conv2.weight', 'module.backbone.layer3.3.bn2.weight', 'module.backbone.layer3.3.bn2.bias', 'module.backbone.layer3.3.bn2.running_mean', 'module.backbone.layer3.3.bn2.running_var', 'module.backbone.layer3.3.bn2.num_batches_tracked', 'module.backbone.layer3.3.conv3.weight', 'module.backbone.layer3.3.bn3.weight', 'module.backbone.layer3.3.bn3.bias', 'module.backbone.layer3.3.bn3.running_mean', 'module.backbone.layer3.3.bn3.running_var', 'module.backbone.layer3.3.bn3.num_batches_tracked', 'module.backbone.layer3.4.conv1.weight', 'module.backbone.layer3.4.bn1.weight', 'module.backbone.layer3.4.bn1.bias', 'module.backbone.layer3.4.bn1.running_mean', 'module.backbone.layer3.4.bn1.running_var', 'module.backbone.layer3.4.bn1.num_batches_tracked', 'module.backbone.layer3.4.conv2.weight', 'module.backbone.layer3.4.bn2.weight', 'module.backbone.layer3.4.bn2.bias', 'module.backbone.layer3.4.bn2.running_mean', 'module.backbone.layer3.4.bn2.running_var', 'module.backbone.layer3.4.bn2.num_batches_tracked', 'module.backbone.layer3.4.conv3.weight', 'module.backbone.layer3.4.bn3.weight', 'module.backbone.layer3.4.bn3.bias', 'module.backbone.layer3.4.bn3.running_mean', 'module.backbone.layer3.4.bn3.running_var', 'module.backbone.layer3.4.bn3.num_batches_tracked', 'module.backbone.layer3.5.conv1.weight', 'module.backbone.layer3.5.bn1.weight', 'module.backbone.layer3.5.bn1.bias', 'module.backbone.layer3.5.bn1.running_mean', 'module.backbone.layer3.5.bn1.running_var', 'module.backbone.layer3.5.bn1.num_batches_tracked', 'module.backbone.layer3.5.conv2.weight', 'module.backbone.layer3.5.bn2.weight', 'module.backbone.layer3.5.bn2.bias', 'module.backbone.layer3.5.bn2.running_mean', 'module.backbone.layer3.5.bn2.running_var', 'module.backbone.layer3.5.bn2.num_batches_tracked', 'module.backbone.layer3.5.conv3.weight', 'module.backbone.layer3.5.bn3.weight', 'module.backbone.layer3.5.bn3.bias', 'module.backbone.layer3.5.bn3.running_mean', 'module.backbone.layer3.5.bn3.running_var', 'module.backbone.layer3.5.bn3.num_batches_tracked', 'module.backbone.layer4.0.conv1.weight', 'module.backbone.layer4.0.bn1.weight', 'module.backbone.layer4.0.bn1.bias', 'module.backbone.layer4.0.bn1.running_mean', 'module.backbone.layer4.0.bn1.running_var', 'module.backbone.layer4.0.bn1.num_batches_tracked', 'module.backbone.layer4.0.conv2.weight', 'module.backbone.layer4.0.bn2.weight', 'module.backbone.layer4.0.bn2.bias', 'module.backbone.layer4.0.bn2.running_mean', 'module.backbone.layer4.0.bn2.running_var', 'module.backbone.layer4.0.bn2.num_batches_tracked', 'module.backbone.layer4.0.conv3.weight', 'module.backbone.layer4.0.bn3.weight', 'module.backbone.layer4.0.bn3.bias', 'module.backbone.layer4.0.bn3.running_mean', 'module.backbone.layer4.0.bn3.running_var', 'module.backbone.layer4.0.bn3.num_batches_tracked', 'module.backbone.layer4.0.downsample.0.weight', 'module.backbone.layer4.0.downsample.1.weight', 'module.backbone.layer4.0.downsample.1.bias', 'module.backbone.layer4.0.downsample.1.running_mean', 'module.backbone.layer4.0.downsample.1.running_var', 'module.backbone.layer4.0.downsample.1.num_batches_tracked', 'module.backbone.layer4.1.conv1.weight', 'module.backbone.layer4.1.bn1.weight', 'module.backbone.layer4.1.bn1.bias', 'module.backbone.layer4.1.bn1.running_mean', 'module.backbone.layer4.1.bn1.running_var', 'module.backbone.layer4.1.bn1.num_batches_tracked', 'module.backbone.layer4.1.conv2.weight', 'module.backbone.layer4.1.bn2.weight', 'module.backbone.layer4.1.bn2.bias', 'module.backbone.layer4.1.bn2.running_mean', 'module.backbone.layer4.1.bn2.running_var', 'module.backbone.layer4.1.bn2.num_batches_tracked', 'module.backbone.layer4.1.conv3.weight', 'module.backbone.layer4.1.bn3.weight', 'module.backbone.layer4.1.bn3.bias', 'module.backbone.layer4.1.bn3.running_mean', 'module.backbone.layer4.1.bn3.running_var', 'module.backbone.layer4.1.bn3.num_batches_tracked', 'module.backbone.layer4.2.conv1.weight', 'module.backbone.layer4.2.bn1.weight', 'module.backbone.layer4.2.bn1.bias', 'module.backbone.layer4.2.bn1.running_mean', 'module.backbone.layer4.2.bn1.running_var', 'module.backbone.layer4.2.bn1.num_batches_tracked', 'module.backbone.layer4.2.conv2.weight', 'module.backbone.layer4.2.bn2.weight', 'module.backbone.layer4.2.bn2.bias', 'module.backbone.layer4.2.bn2.running_mean', 'module.backbone.layer4.2.bn2.running_var', 'module.backbone.layer4.2.bn2.num_batches_tracked', 'module.backbone.layer4.2.conv3.weight', 'module.backbone.layer4.2.bn3.weight', 'module.backbone.layer4.2.bn3.bias', 'module.backbone.layer4.2.bn3.running_mean', 'module.backbone.layer4.2.bn3.running_var', 'module.backbone.layer4.2.bn3.num_batches_tracked', 'module.projector.0.weight', 'module.projector.1.weight', 'module.projector.1.bias', 'module.projector.1.running_mean', 'module.projector.1.running_var', 'module.projector.1.num_batches_tracked', 'module.projector.3.weight', 'module.projector.4.weight', 'module.projector.4.bias', 'module.projector.4.running_mean', 'module.projector.4.running_var', 'module.projector.4.num_batches_tracked', 'module.projector.6.weight', 'module.bn.running_mean', 'module.bn.running_var', 'module.bn.num_batches_tracked'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/braindat/lab/chenyd/MODEL/MSD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(datasets) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    train_files = data[\"training\"]\n",
    "    val_files = data[\"test\"]\n",
    "    labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    RandSpatialCropd,\n",
    ")\n",
    "from resunet import ResUNet\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1,1,1),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        \n",
    "        # RandCropByPosNegLabeld(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     label_key=\"label\",\n",
    "        #     spatial_size=patch_size,\n",
    "        #     pos=1,\n",
    "        #     neg=1,\n",
    "        #     num_samples=4,\n",
    "        #     image_key=\"image\",\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "        RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=(100,100,100),\n",
    "            random_size=False,\n",
    "        ),\n",
    "\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 130)\n",
      "(320, 320, 110)\n",
      "(320, 320, 120)\n",
      "(320, 320, 130)\n",
      "(320, 320, 100)\n",
      "(320, 320, 120)\n",
      "(320, 320, 120)\n",
      "(320, 320, 120)\n",
      "(320, 320, 90)\n",
      "(320, 320, 120)\n",
      "(320, 320, 122)\n",
      "(320, 320, 100)\n",
      "(320, 320, 110)\n",
      "(320, 320, 100)\n",
      "(320, 320, 110)\n",
      "(320, 320, 110)\n",
      "(320, 320, 120)\n",
      "(320, 320, 120)\n",
      "(320, 320, 109)\n",
      "(320, 320, 110)\n",
      "(400, 400, 180)\n",
      "(320, 320, 140)\n",
      "(400, 400, 180)\n",
      "(320, 320, 110)\n",
      "(320, 320, 137)\n",
      "(320, 320, 120)\n",
      "(320, 320, 100)\n",
      "(320, 320, 120)\n",
      "(320, 320, 100)\n",
      "(320, 320, 110)\n"
     ]
    }
   ],
   "source": [
    "def get_nii_data(path):\n",
    "    nii = nib.load(path)\n",
    "    data = nii.get_fdata()\n",
    "    return data.shape\n",
    "\n",
    "data_path = sorted(glob(os.path.join('/data/ydchen/EM_pretraining_data/MSD/Task02_Heart', 'imag*', '*.nii.gz')))\n",
    "for i in data_path:\n",
    "    print(get_nii_data(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 140)\n"
     ]
    }
   ],
   "source": [
    "path = '/data/ydchen/EM_pretraining_data/MSD/Task02_Heart/imagesTs/la_002.nii.gz'\n",
    "img = nib.load(path)\n",
    "img = img.get_fdata()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 24/24 [00:50<00:00,  2.10s/it]\n",
      "Loading dataset: 100%|██████████| 6/6 [00:12<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/braindat/lab/chenyd/DATASET/MSD/Task01_BrainTumour/\"\n",
    "split_json = \"dataset.json\"\n",
    "\n",
    "datasets = data_dir + split_json\n",
    "datalist = load_decathlon_datalist(datasets, True, \"training\")\n",
    "total_len = len(datalist)\n",
    "trainlist = datalist[: int(total_len * 0.9)]\n",
    "val_files = datalist[int(total_len * 0.9) :]\n",
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=trainlist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=8,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss))\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val)\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "max_iterations = 25000\n",
    "eval_num = 500\n",
    "post_label = AsDiscrete(to_onehot=14)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=14)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "# while global_step < max_iterations:\n",
    "#     global_step, dice_val_best, global_step_best = train(global_step, train_loader, dice_val_best, global_step_best)\n",
    "# model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 96, 96, 96])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 96, 96, 96).cuda()\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    x, y = (batch[\"image\"], batch[\"label\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdc55d49b10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0, 0, 48, :, :].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task task7 patch size is [40, 224, 224]\n",
      "task task10 patch size is [56, 192, 192]\n",
      "task task5 patch size is [20, 320, 256]\n",
      "task task6 patch size is [80, 192, 160]\n",
      "task task3 patch size is [128, 128, 128]\n",
      "task task8 patch size is [64, 192, 192]\n",
      "task task1 patch size is [128, 128, 128]\n",
      "task task4 patch size is [40, 56, 40]\n",
      "task task2 patch size is [80, 192, 160]\n",
      "task task9 patch size is [64, 192, 160]\n"
     ]
    }
   ],
   "source": [
    "path = glob(os.path.join('/data/ydchen/EM_pretraining_data/MSD_json','ta*','nnUNetPlans.json'))\n",
    "for i in path:\n",
    "    with open(i) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        patch_size = data['configurations']['3d_fullres']['patch_size']\n",
    "        print(f'task {i.split(\"/\")[-2]} patch size is {patch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 192, 160]\n",
      "(192, 160, 64)\n"
     ]
    }
   ],
   "source": [
    "print(patch_size)\n",
    "patch_size = np.array(patch_size)\n",
    "# permute\n",
    "patch_size = patch_size[[1,2,0]]\n",
    "print(tuple(patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160, 64, 192]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_size[0], patch_size[1], patch_size[2] = patch_size[2], patch_size[0], patch_size[1]\n",
    "patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nii(path):\n",
    "    img = nib.load(path)\n",
    "    img = img.get_fdata()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = glob(os.path.join('/data/ydchen/EM_pretraining_data/MSD','Task03*','im*','*gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task Task03_Liver image shape is (512, 512, 751)\n",
      "task Task03_Liver image shape is (512, 512, 366)\n",
      "task Task03_Liver image shape is (512, 512, 756)\n",
      "task Task03_Liver image shape is (512, 512, 129)\n",
      "task Task03_Liver image shape is (512, 512, 630)\n",
      "task Task03_Liver image shape is (512, 512, 517)\n",
      "task Task03_Liver image shape is (512, 512, 541)\n",
      "task Task03_Liver image shape is (512, 512, 333)\n",
      "task Task03_Liver image shape is (512, 512, 122)\n",
      "task Task03_Liver image shape is (512, 512, 826)\n",
      "task Task03_Liver image shape is (512, 512, 113)\n",
      "task Task03_Liver image shape is (512, 512, 629)\n",
      "task Task03_Liver image shape is (512, 512, 155)\n",
      "task Task03_Liver image shape is (512, 512, 696)\n",
      "task Task03_Liver image shape is (512, 512, 119)\n",
      "task Task03_Liver image shape is (512, 512, 861)\n",
      "task Task03_Liver image shape is (512, 512, 683)\n",
      "task Task03_Liver image shape is (512, 512, 677)\n",
      "task Task03_Liver image shape is (512, 512, 781)\n",
      "task Task03_Liver image shape is (512, 512, 836)\n",
      "task Task03_Liver image shape is (512, 512, 230)\n",
      "task Task03_Liver image shape is (512, 512, 105)\n",
      "task Task03_Liver image shape is (512, 512, 424)\n",
      "task Task03_Liver image shape is (512, 512, 124)\n",
      "task Task03_Liver image shape is (512, 512, 501)\n",
      "task Task03_Liver image shape is (512, 512, 841)\n",
      "task Task03_Liver image shape is (512, 512, 751)\n",
      "task Task03_Liver image shape is (512, 512, 254)\n",
      "task Task03_Liver image shape is (512, 512, 689)\n",
      "task Task03_Liver image shape is (512, 512, 260)\n",
      "task Task03_Liver image shape is (512, 512, 139)\n",
      "task Task03_Liver image shape is (512, 512, 244)\n",
      "task Task03_Liver image shape is (512, 512, 91)\n",
      "task Task03_Liver image shape is (512, 512, 245)\n",
      "task Task03_Liver image shape is (512, 512, 654)\n",
      "task Task03_Liver image shape is (512, 512, 338)\n",
      "task Task03_Liver image shape is (512, 512, 908)\n",
      "task Task03_Liver image shape is (512, 512, 463)\n",
      "task Task03_Liver image shape is (512, 512, 541)\n",
      "task Task03_Liver image shape is (512, 512, 645)\n",
      "task Task03_Liver image shape is (512, 512, 455)\n",
      "task Task03_Liver image shape is (512, 512, 519)\n",
      "task Task03_Liver image shape is (512, 512, 227)\n",
      "task Task03_Liver image shape is (512, 512, 896)\n",
      "task Task03_Liver image shape is (512, 512, 671)\n",
      "task Task03_Liver image shape is (512, 512, 168)\n",
      "task Task03_Liver image shape is (512, 512, 846)\n",
      "task Task03_Liver image shape is (512, 512, 165)\n",
      "task Task03_Liver image shape is (512, 512, 391)\n",
      "task Task03_Liver image shape is (512, 512, 193)\n",
      "task Task03_Liver image shape is (512, 512, 422)\n",
      "task Task03_Liver image shape is (512, 512, 432)\n",
      "task Task03_Liver image shape is (512, 512, 461)\n",
      "task Task03_Liver image shape is (512, 512, 104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4338/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2790395979.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4338/2790395979.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4338/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3768510918.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read_nii</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4338/3768510918.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/nibabel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataobj_images.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">355</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_fdata</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">352 │   │   # Always return requested data type</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">353 │   │   # For array proxies, will attempt to confine data array to dtype</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">354 │   │   # during scaling</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>355 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = np.asanyarray(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataobj, dtype=dtype)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> caching == <span style=\"color: #808000; text-decoration-color: #808000\">'fill'</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fdata_cache = data                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/nibabel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrayproxy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">370</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__array__</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">367 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">array</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">Scaled image data with type `dtype`.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">369 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>370 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>arr = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_scaled(dtype=dtype, slicer=())                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">371 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">372 │   │   │   </span>arr = arr.astype(dtype, copy=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">373 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> arr                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/nibabel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrayproxy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">337</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_scaled</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> np.can_cast(scl_inter, use_dtype):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">335 │   │   │   </span>scl_inter = scl_inter.astype(use_dtype)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">336 │   │   # Read array and upcast as necessary for big slopes, intercepts</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>337 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>scaled = apply_read_scaling(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_unscaled(slicer=slicer), scl_slope, scl_in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">338 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">339 │   │   │   </span>scaled = scaled.astype(np.promote_types(scaled.dtype, dtype), copy=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">340 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> scaled                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/nibabel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrayproxy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">316</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_unscaled</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">313 │   │   │   │   │   │   │   │   │      </span>fileobj,                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">314 │   │   │   │   │   │   │   │   │      </span>offset=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._offset,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">315 │   │   │   │   │   │   │   │   │      </span>order=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.order,                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>316 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │      </span>mmap=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._mmap)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">317 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_fileobj() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> fileobj:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">318 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fileslice(fileobj,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">319 │   │   │   │   │   │   │    </span>slicer,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/nibabel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">volumeutils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">461</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">array_from_file</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 458 │   </span>infile.seek(offset)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 459 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(infile, <span style=\"color: #808000; text-decoration-color: #808000\">'readinto'</span>):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 460 │   │   </span>data_bytes = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">bytearray</span>(n_bytes)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 461 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>n_read = infile.readinto(data_bytes)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 462 │   │   </span>needs_copy = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 463 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 464 │   │   </span>data_bytes = infile.read(n_bytes)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gzip.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">287</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">284 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mode != READ:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">errno</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span>(errno.EBADF, <span style=\"color: #808000; text-decoration-color: #808000\">\"read() on write-only GzipFile object\"</span>)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>287 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._buffer.read(size)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">288 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">289 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read1</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, size=-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">290 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Implements BufferedIOBase.read1()</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_compression.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">68</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">readinto</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">readinto</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, b):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">memoryview</span>(b) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> view, view.cast(<span style=\"color: #808000; text-decoration-color: #808000\">\"B\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> byte_view:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 68 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.read(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(byte_view))                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 │   │   │   </span>byte_view[:<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(data)] = data                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(data)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gzip.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">496</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">read</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">493 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EOFError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Compressed file ended before the \"</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">494 │   │   │   │   │   │   │      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"end-of-stream marker was reached\"</span>)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">495 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>496 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._add_read_data( uncompress )                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">497 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pos += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(uncompress)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> uncompress                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gzip.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_add_read_data</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> uncompress                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">500 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_add_read_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, data):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._crc = zlib.crc32(data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._crc)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._stream_size = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._stream_size + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(data)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">503 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">504 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_read_eof</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4338/\u001b[0m\u001b[1;33m2790395979.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4338/2790395979.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4338/\u001b[0m\u001b[1;33m3768510918.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92mread_nii\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4338/3768510918.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/nibabel/\u001b[0m\u001b[1;33mdataobj_images.py\u001b[0m:\u001b[94m355\u001b[0m in \u001b[92mget_fdata\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Always return requested data type\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# For array proxies, will attempt to confine data array to dtype\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# during scaling\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m355 \u001b[2m│   │   \u001b[0mdata = np.asanyarray(\u001b[96mself\u001b[0m._dataobj, dtype=dtype)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m caching == \u001b[33m'\u001b[0m\u001b[33mfill\u001b[0m\u001b[33m'\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._fdata_cache = data                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/nibabel/\u001b[0m\u001b[1;33marrayproxy.py\u001b[0m:\u001b[94m370\u001b[0m in \u001b[92m__array__\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33marray\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mScaled image data with type `dtype`.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   \u001b[0marr = \u001b[96mself\u001b[0m._get_scaled(dtype=dtype, slicer=())                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dtype \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   \u001b[0marr = arr.astype(dtype, copy=\u001b[94mFalse\u001b[0m)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m arr                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/nibabel/\u001b[0m\u001b[1;33marrayproxy.py\u001b[0m:\u001b[94m337\u001b[0m in \u001b[92m_get_scaled\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m np.can_cast(scl_inter, use_dtype):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   │   \u001b[0mscl_inter = scl_inter.astype(use_dtype)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m336 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Read array and upcast as necessary for big slopes, intercepts\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m337 \u001b[2m│   │   \u001b[0mscaled = apply_read_scaling(\u001b[96mself\u001b[0m._get_unscaled(slicer=slicer), scl_slope, scl_in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dtype \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2m│   │   │   \u001b[0mscaled = scaled.astype(np.promote_types(scaled.dtype, dtype), copy=\u001b[94mFalse\u001b[0m)      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m340 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m scaled                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/nibabel/\u001b[0m\u001b[1;33marrayproxy.py\u001b[0m:\u001b[94m316\u001b[0m in \u001b[92m_get_unscaled\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m313 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │      \u001b[0mfileobj,                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m314 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │      \u001b[0moffset=\u001b[96mself\u001b[0m._offset,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m315 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │      \u001b[0morder=\u001b[96mself\u001b[0m.order,                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m316 \u001b[2m│   │   │   │   │   │   │   │   │      \u001b[0mmmap=\u001b[96mself\u001b[0m._mmap)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m317 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._get_fileobj() \u001b[94mas\u001b[0m fileobj:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m318 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m fileslice(fileobj,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m319 \u001b[0m\u001b[2m│   │   │   │   │   │   │    \u001b[0mslicer,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/nibabel/\u001b[0m\u001b[1;33mvolumeutils.py\u001b[0m:\u001b[94m461\u001b[0m in \u001b[92marray_from_file\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 458 \u001b[0m\u001b[2m│   \u001b[0minfile.seek(offset)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 459 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(infile, \u001b[33m'\u001b[0m\u001b[33mreadinto\u001b[0m\u001b[33m'\u001b[0m):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 460 \u001b[0m\u001b[2m│   │   \u001b[0mdata_bytes = \u001b[96mbytearray\u001b[0m(n_bytes)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 461 \u001b[2m│   │   \u001b[0mn_read = infile.readinto(data_bytes)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 462 \u001b[0m\u001b[2m│   │   \u001b[0mneeds_copy = \u001b[94mFalse\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 463 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 464 \u001b[0m\u001b[2m│   │   \u001b[0mdata_bytes = infile.read(n_bytes)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/\u001b[0m\u001b[1;33mgzip.py\u001b[0m:\u001b[94m287\u001b[0m in \u001b[92mread\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m284 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.mode != READ:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96merrno\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mOSError\u001b[0m(errno.EBADF, \u001b[33m\"\u001b[0m\u001b[33mread() on write-only GzipFile object\u001b[0m\u001b[33m\"\u001b[0m)             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m287 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._buffer.read(size)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mread1\u001b[0m(\u001b[96mself\u001b[0m, size=-\u001b[94m1\u001b[0m):                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\"\"Implements BufferedIOBase.read1()\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/\u001b[0m\u001b[1;33m_compression.py\u001b[0m:\u001b[94m68\u001b[0m in \u001b[92mreadinto\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mreadinto\u001b[0m(\u001b[96mself\u001b[0m, b):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mmemoryview\u001b[0m(b) \u001b[94mas\u001b[0m view, view.cast(\u001b[33m\"\u001b[0m\u001b[33mB\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mas\u001b[0m byte_view:                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 68 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.read(\u001b[96mlen\u001b[0m(byte_view))                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   │   \u001b[0mbyte_view[:\u001b[96mlen\u001b[0m(data)] = data                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlen\u001b[0m(data)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/\u001b[0m\u001b[1;33mgzip.py\u001b[0m:\u001b[94m496\u001b[0m in \u001b[92mread\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m493 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEOFError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mCompressed file ended before the \u001b[0m\u001b[33m\"\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m494 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mend-of-stream marker was reached\u001b[0m\u001b[33m\"\u001b[0m)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m495 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m496 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._add_read_data( uncompress )                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m497 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._pos += \u001b[96mlen\u001b[0m(uncompress)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m uncompress                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/\u001b[0m\u001b[1;33mgzip.py\u001b[0m:\u001b[94m501\u001b[0m in \u001b[92m_add_read_data\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m uncompress                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m500 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_add_read_data\u001b[0m(\u001b[96mself\u001b[0m, data):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m501 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._crc = zlib.crc32(data, \u001b[96mself\u001b[0m._crc)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._stream_size = \u001b[96mself\u001b[0m._stream_size + \u001b[96mlen\u001b[0m(data)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m503 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m504 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_read_eof\u001b[0m(\u001b[96mself\u001b[0m):                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in data_path:\n",
    "    img = read_nii(i)\n",
    "    print(f'task {i.split(\"/\")[-3]} image shape is {img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 20 11:06:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 24%   49C    P2   218W / 250W |   6047MiB / 11178MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 23%   60C    P2   134W / 250W |   5259MiB / 11178MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('/data/ydchen/EM_pretraining_data/BarlowClip/testgenerate_then_optimize_pretrain_7000_iterations_encoder.pth',\n",
    "                     map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
