{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import ViT as Vit_monai\n",
    "from vit_pytorch.vit_3d import ViT as Vit\n",
    "from monai.networks.nets import UNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdasfdfsdfgsdg\n",
      "this is a test ddddddddddddddddddddddddddddddddd\n",
      "this is a test\n"
     ]
    }
   ],
   "source": [
    "print('asdasfdfsdfgsdg')\n",
    "print('this is a test ddddddddddddddddddddddddddddddddd',flush=True)\n",
    "print('this is a test',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  6 06:32:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 20%   19C    P8     7W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 24%   21C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import UNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrPrUpBlock, UnetrUpBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 16\n",
    "norm_name = \"instance\"\n",
    "res_block = True\n",
    "upblock = UnetrUpBlock(\n",
    "            spatial_dims=3,\n",
    "            in_channels=feature_size * 2,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=res_block,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 32, 160, 160])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec1 = torch.randn(1,32,16,80,80)\n",
    "enc1 = torch.randn(1,16,32,160,160)\n",
    "upblock(dec1, enc1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec1 = torch.randn(1, 32, 64, 80, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 128, 160, 160])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upblock.transp_conv(dec1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/code/SuperHuman-main/scripts/scripts')\n",
    "from model_superhuman import UNet_PNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取cfg\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "from unetr import UNETR\n",
    "import torch\n",
    "cfg_file = 'seg_3d.yaml'\n",
    "with open('/code/SuperHuman-main/scripts/scripts/config/' + cfg_file, 'r') as f:\n",
    "        cfg = AttrDict(yaml.safe_load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "superhuman =  UNet_PNI(in_planes=cfg.MODEL.input_nc,\n",
    "                        out_planes=cfg.MODEL.output_nc,\n",
    "                        filters=cfg.MODEL.filters,\n",
    "                        upsample_mode=cfg.MODEL.upsample_mode,\n",
    "                        decode_ratio=cfg.MODEL.decode_ratio,\n",
    "                        merge_mode=cfg.MODEL.merge_mode,\n",
    "                        pad_mode=cfg.MODEL.pad_mode,\n",
    "                        bn_mode=cfg.MODEL.bn_mode,\n",
    "                        relu_mode=cfg.MODEL.relu_mode,\n",
    "                        init_mode=cfg.MODEL.init_mode).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet_PNI(\n",
       "  (embed_in): Sequential(\n",
       "    (0): Conv3d(1, 28, kernel_size=(1, 5, 5), stride=(1, 1, 1), padding=(0, 2, 2))\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (conv0): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(28, 28, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(28, 28, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(28, 28, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (pool0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(28, 36, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(36, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(48, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (pool3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (center): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(64, 80, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(80, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(80, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(80, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(80, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (up0): Sequential(\n",
       "    (0): Upsample(scale_factor=(1.0, 2.0, 2.0), mode=trilinear)\n",
       "    (1): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (cat0): Sequential(\n",
       "    (0): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (conv4): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): Upsample(scale_factor=(1.0, 2.0, 2.0), mode=trilinear)\n",
       "    (1): Conv3d(64, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (cat1): Sequential(\n",
       "    (0): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (conv5): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(48, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): Upsample(scale_factor=(1.0, 2.0, 2.0), mode=trilinear)\n",
       "    (1): Conv3d(48, 36, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (cat2): Sequential(\n",
       "    (0): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (conv6): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(36, 36, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(36, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): Upsample(scale_factor=(1.0, 2.0, 2.0), mode=trilinear)\n",
       "    (1): Conv3d(36, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (cat3): Sequential(\n",
       "    (0): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (conv7): resBlock_pni(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(28, 28, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(28, 28, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0, inplace=True)\n",
       "      (3): Conv3d(28, 28, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (block3): BatchNorm3d(28, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (block4): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (embed_out): Sequential(\n",
       "    (0): Conv3d(28, 28, kernel_size=(1, 5, 5), stride=(1, 1, 1), padding=(0, 2, 2))\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (out_put): Sequential(\n",
       "    (0): Conv3d(28, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superhuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unetr_path = '/data/cyd0806/superhuman/models/UNETR32*160*160_patch8*16*16_1230/2022-12-29--16-51-31_seg_3d/model-090000.pt'\n",
    "unetr_states = torch.load(unetr_path)\n",
    "unetr_states_dict = unetr_states['model_weights']\n",
    "unetr_states_dict_new = {}\n",
    "for key in unetr_states_dict.keys():\n",
    "    unetr_states_dict_new[key[7:]] = unetr_states_dict[key]\n",
    "\n",
    "vit_state = torch.load('/data/cyd0806/EM_raw_image/MAE/32*160*160_4*16*16_batch_1_mask0.75_1231/mae_vit_model_1220_32*160*160_200.pth')\n",
    "vit_state_dict = vit_state['model_weights']\n",
    "vit_state_dict_new = {}\n",
    "for key in vit_state_dict.keys():\n",
    "    vit_state_dict_new['vit.'+key] = vit_state_dict[key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['encoder1.layer.conv1.conv.weight', 'encoder1.layer.conv2.conv.weight', 'encoder1.layer.conv3.conv.weight', 'encoder2.transp_conv_init.conv.weight', 'encoder2.blocks.0.0.conv.weight', 'encoder2.blocks.0.1.conv1.conv.weight', 'encoder2.blocks.0.1.conv2.conv.weight', 'encoder2.blocks.1.0.conv.weight', 'encoder2.blocks.1.1.conv1.conv.weight', 'encoder2.blocks.1.1.conv2.conv.weight', 'encoder3.transp_conv_init.conv.weight', 'encoder3.blocks.0.0.conv.weight', 'encoder3.blocks.0.1.conv1.conv.weight', 'encoder3.blocks.0.1.conv2.conv.weight', 'encoder4.transp_conv_init.conv.weight', 'decoder5.transp_conv.conv.weight', 'decoder5.conv_block.conv1.conv.weight', 'decoder5.conv_block.conv2.conv.weight', 'decoder5.conv_block.conv3.conv.weight', 'decoder4.transp_conv.conv.weight', 'decoder4.conv_block.conv1.conv.weight', 'decoder4.conv_block.conv2.conv.weight', 'decoder4.conv_block.conv3.conv.weight', 'decoder3.transp_conv.conv.weight', 'decoder3.conv_block.conv1.conv.weight', 'decoder3.conv_block.conv2.conv.weight', 'decoder3.conv_block.conv3.conv.weight', 'decoder2.transp_conv.conv.weight', 'decoder2.conv_block.conv1.conv.weight', 'decoder2.conv_block.conv2.conv.weight', 'decoder2.conv_block.conv3.conv.weight', 'dtrans.weight', 'out.conv.conv.weight', 'out.conv.conv.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr = UNETR(\n",
    "                        in_channels=cfg.MODEL.input_nc,\n",
    "                        out_channels=cfg.MODEL.output_nc,\n",
    "                        img_size=cfg.MODEL.unetr_size,\n",
    "                        patch_size=(4,16,16),\n",
    "                        kernel_size=(1,3,3),\n",
    "                        feature_size=16,\n",
    "                        hidden_size=768,\n",
    "                        mlp_dim=3072,\n",
    "                        num_heads=12,\n",
    "                        pos_embed='perceptron',\n",
    "                        norm_name='instance',\n",
    "                        conv_block=True,\n",
    "                        res_block=True,\n",
    "                        dropout_rate=0.1).cuda()\n",
    "unetr.load_state_dict(vit_state_dict_new,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.randn(1,1,32,160,160).cuda()\n",
    "x, hidden_states_out,_ = unetr.vit(x_in)\n",
    "enc1 = unetr.encoder1(x_in)\n",
    "x2 = hidden_states_out[3]\n",
    "enc2 = unetr.encoder2(unetr.proj_feat(x2, unetr.hidden_size, unetr.feat_size))\n",
    "x3 = hidden_states_out[6]\n",
    "enc3 = unetr.encoder3(unetr.proj_feat(x3, unetr.hidden_size, unetr.feat_size))\n",
    "x4 = hidden_states_out[9]\n",
    "enc4 = unetr.encoder4(unetr.proj_feat(x4, unetr.hidden_size, unetr.feat_size))\n",
    "dec4 = unetr.proj_feat(x, unetr.hidden_size, unetr.feat_size)\n",
    "dec3 = unetr.decoder5(dec4, enc4)\n",
    "dec2 = unetr.decoder4(dec3, enc3)\n",
    "dec1 = unetr.decoder3(dec2, enc2)\n",
    "if unetr.patch_size[0] != unetr.patch_size[1]:\n",
    "    dec1 = unetr.dtrans(dec1)\n",
    "out = unetr.decoder2(dec1, enc1)\n",
    "logits = unetr.out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 160, 160])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "unetr.decoder5.transp_conv = nn.ConvTranspose3d(768, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 8, 10, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 8, 20, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.decoder5.transp_conv(dec4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_params = []\n",
    "other_params = []\n",
    "for name,weight in unetr.named_parameters():\n",
    "    if name not in vit_state_dict_new.keys():\n",
    "        pretrained_params.append(weight)\n",
    "    else:\n",
    "        other_params.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_params = []\n",
    "other_params = []\n",
    "for name,weight in unetr.named_parameters():\n",
    "    if name not in vit_state_dict_new.keys():\n",
    "        pretrained_params.append(weight)\n",
    "    else:\n",
    "        other_params.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置不同学习率\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': pretrained_params, 'lr': 1e-4},\n",
    "    {'params': other_params, 'lr': 1e-3}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "for group in optimizer.param_groups:\n",
    "    print(group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from attrdict import AttrDict\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "# parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "# parser.add_argument('--momentum', type=float, default=0.9)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = AttrDict()\n",
    "args.learning_rate = 1e-3\n",
    "args.weight_decay = 1e-4\n",
    "args.momentum = 0.9\n",
    "\n",
    "\n",
    "all_params = unetr.parameters()\n",
    "weight_params = []\n",
    "quant_params = []\n",
    "# 根据自己的筛选规则 将所有网络参数进行分组\n",
    "for pname, p in unetr.named_parameters():\n",
    "    if any([pname.endswith(k) for k in ['cw', 'dw', 'cx', 'dx', 'lamb']]):\n",
    "        quant_params += [p]\n",
    "    elif ('conv' or 'fc' in pname and 'weight' in pname):\n",
    "        weight_params += [p]    \n",
    "# 取回分组参数的id\n",
    "params_id = list(map(id, weight_params)) + list(map(id, quant_params))\n",
    "# 取回剩余分特殊处置参数的id\n",
    "other_params = list(filter(lambda p: id(p) not in params_id, all_params))\n",
    "# 构建不同学习参数的优化器\n",
    "optimizer = torch.optim.SGD([\n",
    "        {'params': other_params}, \n",
    "        {'params': quant_params, 'lr': 0.1*args.learning_rate},\n",
    "        {'params': weight_params, 'weight_decay': args.weight_decay}],\n",
    "        lr=args.learning_rate,\n",
    "        momentum=args.momentum,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 4, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.decoder5.transp_conv(torch.randn(1,768,4,16,16).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvTranspose3d(768, 128, kernel_size=(1, 2, 2), stride=(1, 2, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.decoder5.transp_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 16, 20, 20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.encoder4.transp_conv_init(torch.randn(1, 768, 8, 10, 10).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.randn(1,124,16,20,20).cuda()\n",
    "for blk in unetr.encoder4.blocks:\n",
    "    x_test = blk(x_test)\n",
    "    print(x_test.shape)\n",
    "#unetr.encoder2.blocks(torch.randn(1,32,16,20,20).cuda()).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 8, 10, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.proj_feat(x2, unetr.hidden_size, unetr.feat_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetrUpBlock(\n",
       "  (transp_conv): Convolution(\n",
       "    (conv): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "  )\n",
       "  (conv_block): UnetResBlock(\n",
       "    (conv1): Convolution(\n",
       "      (conv): Conv3d(32, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): Convolution(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "    )\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (norm1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (norm2): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (conv3): Convolution(\n",
       "      (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (norm3): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.decoder2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 128, 160, 160])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.decoder2.transp_conv(torch.randn(1,32,64,80,80).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(unetr.patch_size[1]/unetr.patch_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16, 80, 80])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(int(unetr.patch_size[1]/unetr.patch_size[0]), 1, 1), padding=(1, 1, 1), bias=False)(torch.randn(1,32,64,80,80)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 8 but got size 16 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2695/2583394387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([1, 128, 16, 20, 20])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdec4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([1, 768, 8, 10, 10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdec3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([1, 128, 16, 20, 20])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([1, 64, 32, 40, 40])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([1, 32, 64, 80, 80])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/monai/networks/blocks/unetr_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, skip)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# number of channels for skip should equals to out_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 8 but got size 16 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "x_in = torch.randn(1,1,32,160,160).cuda() # patch_size=(4,16,16)\n",
    "x, hidden_states_out,_ = unetr.vit(x_in) #(1,800,768) \n",
    "enc1 = unetr.encoder1(x_in) # torch.Size([1, 16, 32, 160, 160])\n",
    "x2 = hidden_states_out[3] # torch.Size([1, 800, 768])\n",
    "enc2 = unetr.encoder2(unetr.proj_feat(x2, unetr.hidden_size, unetr.feat_size)) # torch.Size([1, 32, 64, 80, 80])\n",
    "x3 = hidden_states_out[6] # torch.Size([1, 800, 768])\n",
    "enc3 = unetr.encoder3(unetr.proj_feat(x3, unetr.hidden_size, unetr.feat_size)) # torch.Size([1, 64, 32, 40, 40])\n",
    "x4 = hidden_states_out[9] # torch.Size([1, 800, 768])\n",
    "enc4 = unetr.encoder4(unetr.proj_feat(x4, unetr.hidden_size, unetr.feat_size)) # torch.Size([1, 128, 16, 20, 20])\n",
    "dec4 = unetr.proj_feat(x, unetr.hidden_size, unetr.feat_size) # torch.Size([1, 768, 8, 10, 10])\n",
    "dec3 = unetr.decoder5(dec4, enc4) # torch.Size([1, 128, 16, 20, 20])\n",
    "dec2 = unetr.decoder4(dec3, enc3) # torch.Size([1, 64, 32, 40, 40])\n",
    "dec1 = unetr.decoder3(dec2, enc2) # torch.Size([1, 32, 64, 80, 80])\n",
    "out = unetr.decoder2(dec1, enc1)\n",
    "logits = unetr.out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 8, 10, 10])\n",
      "torch.Size([1, 32, 16, 20, 20])\n",
      "torch.Size([1, 32, 32, 40, 40])\n",
      "torch.Size([1, 32, 64, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "shape1 = unetr.proj_feat(x2, unetr.hidden_size, unetr.feat_size).shape\n",
    "print(shape1)\n",
    "test_data = torch.randn(shape1).cuda()\n",
    "shape2 = unetr.encoder2.transp_conv_init(torch.randn(test_data.shape).cuda()).shape\n",
    "print(shape2)\n",
    "test_data2 = unetr.encoder2.transp_conv_init(torch.randn(test_data.shape).cuda())\n",
    "for blk in unetr.encoder2.blocks:\n",
    "    test_data2 = blk(test_data2)\n",
    "    print(test_data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 2, 10, 10])\n",
      "torch.Size([1, 32, 4, 20, 20])\n",
      "torch.Size([1, 32, 8, 40, 40])\n",
      "torch.Size([1, 32, 16, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "shape1 = unetr2.proj_feat(x2, unetr2.hidden_size, unetr2.feat_size).shape\n",
    "print(shape1)\n",
    "test_data = torch.randn(shape1).cuda()\n",
    "shape2 = unetr2.encoder2.transp_conv_init(torch.randn(test_data.shape).cuda()).shape\n",
    "print(shape2)\n",
    "test_data2 = unetr2.encoder2.transp_conv_init(torch.randn(test_data.shape).cuda())\n",
    "for blk in unetr2.encoder2.blocks:\n",
    "    test_data2 = blk(test_data2)\n",
    "    print(test_data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unetr2 = UNETR(\n",
    "                        in_channels=cfg.MODEL.input_nc,\n",
    "                        out_channels=cfg.MODEL.output_nc,\n",
    "                        img_size=cfg.MODEL.unetr_size,\n",
    "                        patch_size=(16,16,16),\n",
    "                        feature_size=16,\n",
    "                        hidden_size=768,\n",
    "                        mlp_dim=3072,\n",
    "                        num_heads=12,\n",
    "                        pos_embed='perceptron',\n",
    "                        norm_name='instance',\n",
    "                        conv_block=True,\n",
    "                        res_block=True,\n",
    "                        dropout_rate=0.1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 2, 10, 10])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr2.proj_feat(x2, unetr2.hidden_size, unetr2.feat_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.randn(1,1,32,160,160).cuda()\n",
    "x, hidden_states_out,_ = unetr2.vit(x_in) # torch.Size([1, 200, 768])\n",
    "enc1 = unetr2.encoder1(x_in) # torch.Size([1, 16, 32, 160, 160])\n",
    "x2 = hidden_states_out[3] # torch.Size([1, 200, 768])\n",
    "enc2 = unetr2.encoder2(unetr2.proj_feat(x2, unetr2.hidden_size, unetr2.feat_size)) # torch.Size([1, 32, 16, 80, 80])\n",
    "x3 = hidden_states_out[6] # torch.Size([1, 200, 768])\n",
    "enc3 = unetr2.encoder3(unetr2.proj_feat(x3, unetr2.hidden_size, unetr2.feat_size)) # torch.Size([1, 64, 8, 40, 40])\n",
    "x4 = hidden_states_out[9] # torch.Size([1, 200, 768])\n",
    "enc4 = unetr2.encoder4(unetr2.proj_feat(x4, unetr2.hidden_size, unetr2.feat_size)) # torch.Size([1, 128, 4, 20, 20])\n",
    "dec4 = unetr2.proj_feat(x, unetr2.hidden_size, unetr2.feat_size) # torch.Size([1, 768, 2, 10, 10])\n",
    "dec3 = unetr2.decoder5(dec4, enc4) # torch.Size([1, 128, 4, 20, 20])\n",
    "dec2 = unetr2.decoder4(dec3, enc3) # torch.Size([1, 64, 8, 40, 40])\n",
    "dec1 = unetr2.decoder3(dec2, enc2) # torch.Size([1, 32, 16, 80, 80])\n",
    "out = unetr2.decoder2(dec1, enc1) # torch.Size([1, 16, 32, 160, 160])\n",
    "logits = unetr2.out(out) # torch.Size([1, 3, 32, 160, 160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16, 20, 20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unetr.encoder2.transp_conv_init(x2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai_vit = unetr.vit\n",
    "mae_vit = Vit(\n",
    "    image_size = 160,          # image size\n",
    "    frames = 32,               # number of frames\n",
    "    image_patch_size = 16,     # image patch size\n",
    "    frame_patch_size = 4,      # frame patch size\n",
    "    channels=1,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vit_pytorch.vit_3d import ViT as Vit\n",
    "from vit_pytorch import MAE\n",
    "x = torch.randn(1,1,32,160,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vit(\n",
    "                        image_size = 160,          # image size\n",
    "                        frames = 32,               # number of frames\n",
    "                        image_patch_size = 16,     # image patch size\n",
    "                        frame_patch_size = 4,      # frame patch size\n",
    "                        channels=1,\n",
    "                        num_classes = 1000,\n",
    "                        dim = 768,\n",
    "                        depth = 12,\n",
    "                        heads = 12,\n",
    "                        mlp_dim = 3072,\n",
    "                        dropout = 0.1,\n",
    "                        emb_dropout = 0.1\n",
    "                    )\n",
    "\n",
    "mae = MAE(\n",
    "    encoder = model,\n",
    "    masking_ratio = 0.75,   # the paper recommended 75% masked patches\n",
    "    decoder_dim = 512,      # paper showed good results with just 512\n",
    "    decoder_depth = 6       # anywhere from 1 to 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 801, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 28 19:39:20 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:60:00.0 Off |                  N/A |\n",
      "| 25%   35C    P2    70W / 250W |   5187MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 24%   24C    P8     8W / 250W |      4MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
